<!DOCTYPE html>
<html>
<head>
    <title>Live Audio Waveform</title>
    <style>
        .waveform-container {
            position: relative;
            width: 150px;
            height: 60px;
            background-color: #333;
            margin-bottom: 10px;
        }

        canvas {
            width: 100%;
            height: 100%;
            display: block;
        }

        .overlay-text {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-weight: bold;
            font-size: 20px;
            text-align: center;
            pointer-events: none;
        }

        button {
            padding: 8px 16px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="waveform-container">
        <div class="overlay-text">
            <div id="primaryInstrumentName">Clarinet</div>
            <div id="primaryInstrumentNote">F4</div>
        </div>
        <canvas id="primaryWaveCanvas" width="400" height="100"></canvas>

    </div>

    <button id="playButton">Play Note</button>

    <script>
        const playButton = document.getElementById("playButton");
        const canvas = document.getElementById("primaryWaveCanvas");
        const ctx = canvas.getContext("2d");

        let audioContext;
        let analyser;
        let sourceNode;
        let dataArray;
        let animationId;
        let audioBuffer;

        async function setupAudio() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 64;

                const response = await fetch("tempaudio/clarinet/F4.mp3");
                const arrayBuffer = await response.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            }
        }

        function drawWaveform() {
            const bufferLength = analyser.fftSize;
            dataArray = new Uint8Array(bufferLength);
            analyser.getByteTimeDomainData(dataArray);

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.lineWidth = 2;
            ctx.strokeStyle = "lime";
            ctx.beginPath();

            const sliceWidth = canvas.width * 1.0 / bufferLength;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 255.0; // normalize to [0, 2]
                const y = v * canvas.height;

                if (i === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }
                x += sliceWidth;
            }

            ctx.lineTo(canvas.width, canvas.height / 2);
            ctx.stroke();

            animationId = requestAnimationFrame(drawWaveform);
        }

        async function playAudio() {
            await setupAudio();

            if (sourceNode) {
                sourceNode.disconnect();
                cancelAnimationFrame(animationId);
            }

            sourceNode = audioContext.createBufferSource();
            sourceNode.buffer = audioBuffer;
            sourceNode.connect(analyser);
            analyser.connect(audioContext.destination);

            sourceNode.start();
            drawWaveform();

            // Stop after 5 seconds

        }

        playButton.addEventListener("click", playAudio);
    </script>
</body>
</html>
