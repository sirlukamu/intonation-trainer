Next Steps:
- Edit full chromatic .wav files into pitch .mp3s
- "Both" unison and octave generator
- Randomize in/out of tune for secondary
- Create adaptive difficulty settings
- Implement buttons for "Reset Difficulty To"
- Second game-mode - if out of tune, then sharp-flat mode (as opposed to in-out mode)
- Range/Instrument compatibility
- Review ChatGPT history and copy/cite all generated code.

##### Summary of Project Planning Discussion ##### 5/31/25

Purpose & Goals - This web app is an educational tool for band teachers and students. By using this app, students will be able to practice identifying when two notes are in tune or not. The website is intended to be used both in classroom settings and for individual practice. Users will hear two notes played together and select "in tune" or "out of tune". If the notes are out of tune, it will be followed by another exercise where the reference tune will start, then the out-of-tune note will join, and the user will select "sharp" or "flat". The user will be given immediate feedback with information on how sharp or flat the note was as a visual tuner graphic and text statement, as well as giving the option to hear the notes again before proceeding to the next question. 

Gamemode Options -
1) Difficulty: Easy, Medium, and Hard. Gives a starting point for the first question, and adjusts as the game goes on. This setting determines how out-of-tune the second pitch will be. When the user answers correctly, it will get gradually more difficult, and if the user is incorrect, it will get gradually easier.
2) Intervals: Unisons, Octaves, or Both. "Unison" will use the exact same pitch (e.g., "A4" for both notes. "Octaves" will play different octaves (e.g., A4 & A3) using a normalized system, which means that if a high Bb is played on one instrument, the second instrument will also try to play their high Bb if it has a different natural range. Otherwise, it will try to pick a note that is either one octave above or below the reference pitch if the second instrument is in the same range, or two octaves above or below.
3) Instruments: to allow for focused practice, there will be an option to select specific instruments using checkboxes for both the primary and secondary notes. 
4) Automatic Playback: All answers, On wrong answers, Off. This allows the user to choose if they want to hear the question played back after guessing before automatically going on to the next question.
5) Playback Options: Mono, Stereo. Allows user to hear notes equally through both speakers or to have the notes panned slightly to different sides.

##### Difficulty #####

easy could be anywhere from 30-50 cents? medium would be from 15-30 cents, hard would be below 15 cents. So if you click on "easy" it resets to 50 cents and gets harder from there. if you click on medium, it starts at 30 cents. hard is 15 cents. but then the program keeps track of correct/incorrect responses and makes the next question harder/easier.

##### List of Instruments and Ranges Planned for Final Version ##### 5/24/25

piccolo, 
flute, 
oboe, 
clarinet, 
bass clarinet, 
bassoon, 
alto sax, 
tenor sax, 
bari sax,
trumpet, 
french horn, 
trombone, 
baritone/euphonium, 
tuba, 
timpani,
grand piano (16)

##### File Size Considerations ##### 5/25/25

A 5-second .mp3 file at 128 kbps is about .5 MB. Since I am planning to record two notes for each pitch, the total file size for each instrument would equal 1MB per note in their full chromatic scale. Piano has the most at 88MB, a 2-octave chromatic scale would be 25MB.

 
##### Design Choice: "True Unison" or "Normal Octaves" Option ##### 5/25/25

True unison means the exact sounding pitch: Bb4 and Bb4. Normal Octaves means that Bb4 is "low" for one instrument and Bb5 is "low" for another, so the "low Bb" could mean different octaves depending on the instrument. This is normal in a concert band context.

There are five main groupings in this project. Lowest: tuba. Low: bass clarinet, bassoon, bari sax, trombone, baritone. Medium: clarinet, alto sax, tenor sax, trumpet, french horn. High: flute, oboe. Highest: piccolo.

The design solution is to have an option where users can toggle between "true unison" and "normal octaves". True unison would limit the secondary pitch to instruments that can play 
in the same octave. (See #Select Compatible Second Instrument# in chatgpt.txt file.) Normal Octaves would allow the secondary pitch to be a different octave, but generally in the same register of both instruments such as "low", "middle", or "high".

To normalize octaves, the logic would use instrument metadata. (See #Example Metadata Format# in chatgpt.txt file.) Using the Medium instruments as reference, Low instruments would be -1 octave, Lowest would be -2, High would be +1, and Highest would be +2. A normalizeOctave(primaryInstr, secondaryInstr) function would parse the octave number from the soundfile of both instruments and find the octave number of the secondary instrument by subtracting primaryInstr.octave from secondaryInstr.octave. For example, normalizeOctave(flute, tuba) would result in [(-2) - (1)] = -3, and the flute's Bb5 would be paired with the tuba's Bb2, both in the "low" register of each instrument. The opposite would also work: normalizeOctave(tuba, flute) would result in [(1) - (-2)] = 3, and the tuba's Bb2 would be paired with the flute's Bb5.

There may still be some issues to work through surrounding certain instruments like French horn. If "low" concert Bb is first space F for horn, putting it in the Medium category, what happens when the primary pitch randomizes as French Horn's low Bb (concert Eb) - an easy note for beginning horn players, but impossible for any other brass instrument? If the user also selects "French Horn" for primary and "Brass" for secondary, there would need to be a logic check in picking the primary pitch that excludes any notes that aren't in the secondary group. {!} OR {!} logic that prefers normalized octaves, but can also fall back on true unisons or alternate octaves. For example, if low Bb (Eb3) is picked for horn, trumpet's first space F (Eb4) could be picked for the secondary pitch.

##### Design Choice: Scope of Project Limited to Unisons and Octaves ##### 5/25/25

The goal of this website is to train students to tune unisons and octaves. Other intervals, such as 5ths or 3rds, are outside the scope of this website. It may be grounds for a future project instead.

##### Getting the Seconday Pitch ##### 5/31/25

once the first pitch is selected randomly (which has already been programmed), how will it know to pick a second pitch? First, I do want to have options here: user can select "unison" or "octaves". when unison is selected, I need to have some kind of tracker. Would I create a "gamemode" variable that is a dictionary of key-value pairs? how do i make sure that at least one is selected? if it's okay to do either-or (it should be). [x]unison [x]octaves - those are the options. [ ]unison [ ]octaves would not be okay (both selected) maybe something that says Please select at least one option. if they leave both unselected and try to play. Can i do something like gamemode.unison = false, gamemode.octaves = false, then (!gamemode.unison) && (!gamemode.octaves) {err}? I need to learn more about inputs, but <input type="checkbox"> and trying to figure out how to use that. Better yet, use a <input type="radio" and include three options: unison, octaves, or both.  Keep in mind that I also plan to use gamemode.primaryinstruments = [{key: "flute" value: "true"} {key: "trumpet" value: "false"} {key: "baritone" value: "false"}] and the same with gamemode.secondaryinstruments. I'm thinking about adding a "brass" and "woodwinds" option, so I'd need to add some metadata to the instruments in my data.js file like trumpet: { family: "brass", octave: 0, pitches: ["F3", ... "F5"]}, flute: {...}

so, if [x]unison is selected, and the computer picks a random instrument and pitch (baritone: Bb2), how will the computer know what the options for a second pitch are? First, look and see which instruments are selected, then look to see if Bb2 is in their list of pitches, make a new temporary list with those instrument names, do Math.floor(Math.random() * templist.length) to randomly choose secondaryInstrument, then if primaryInstrument = secondaryInstrument and if generatedTone = `${selectedPitch}-a`, choose `${selectedPitch}-b.mp3`, else choose `${selectedPitch}-a.mp3`. if primaryInstrument != secondaryInstrument, then do if Math.random() < .5 ? `${selectedPitch}-a.mp3` : `${selectedPitch}-b.mp3`

now, if [x]octave is selected... can i parse the int from the filename? currentOctave = parseInt(selectedPitch) - if the pitch is Bb3, would it return "3"? then something like currentOctave = currentOctave + instrument.octave (flute is +1, baritone is -1) - again, the point is to prioritize normalized octaves, so low Bb on trumpet would be low Bb on flute. Do we randomize the instrument first, then find an octave, preferring the normalized? Yes, I think so. as an example, primaryInstrument is trumpet, selectedPitch is Bb3. secondaryInstrument is flute, how do I know what note to pick? Well, parseInt(selectedPitch) gives me 3, flute.octave gives me +1, so I look for Bb4. Can I do a parseTest(selectedPitch)? noteName = parseText(selectedPitch), then if `{noteName}${currentOctave}` is in instrument.pitches, version = Math.random() < .5 ? "-a" : "-b"; fetch(`${instrument}/${noteName}${currentOctave}${version}`;
Note: instead of parseText or parseInt, use string slicing (see note in chatgpt.txt)
but what if secondaryInstrument is clarinet? normalized octave would be unison


##### Recording Option - Computer Generated #####

I'm working on getting some of the files to just be computer generated. I was trying to use Finale and Audacity to loopback record, when I realized two things: Finale can easily export a file to .wav - instantly creating all of the pitches needed, and Finale can access the VST plugins for autotuning, which is nice because it adds some "human playback" effect of not generating perfectly in-tune notes. There are a lot of settings to tinker with, and unfortunately some of the resulting notes are unusable but others are perfect.

I have spent so much time on this. I've tried generating audio and using Autotuners like MAutoTune and Graillon3, but even though the pitch is steady, the volume pulses like it was still out of tune. I tried downloading other VST libraries: BBC Orchestra, Berlin OT. I've even tried downloading and using MuseScore instead of Finale. Here's finally one that might work, at least for flute, and it's back to the old Finale and Garritan instruments.

In the MIDI/Audio > VST Banks & Effects... selecting the standard ARIA Player, but then clicking on the Edit icon, clicking on channel 1, brings up an option to slect FlutePlr1. For whatever reason, that took away the vibrato. Then in Effects > Graillon 3, I used Smooth: hard, Inertia: 20%, Snap Min: 1.00, and then I set Comp: 100%

Now, instead of trying to set these perfectly over and over again, just do "Save As" and the next instrument name: oboe.

##### Range options #####

Since I've decided to use computer generated sounds for now, I think I can spend a little more time on the range options. The idea is to allow the user to select certain ranges - let's start with [ ]High [ ]Middle and [ ]Low. It's checkboxes, so they can select more than one. (If they don't select one, it gives a "Please select at least one box for ranges." Why? This lets students practice specific areas. I know my weakness is in hearing low notes. For simplicity, High means any note in octaves 5-6, Medium is octave 4, and low is anything in octaves 2-3. That covers all the instrument ranges - excluding piccolo for now.

##### Understanding GitHub Commit Commands #####

I want to develop a professional workflow, so I will start using commit messages more conventionally. 

Using "git status" shows which files I have changed compared to what is currently uploaded to GitHub. This allows me to decide what I need to pull or commit.

I can run "git diff" to see exactly what I have changed during the current work session. Then, I can use "git add {filename}" to "stage" that file for committing. It is good practice to stage one file at a time (unless they are logically grouped together). 

Finally, I run "git commit" to open up a message editor, add a short subject line, press enter twice, then add a longer body comment explaining the change in more detail, save and close the file, then run "git push" to upload the changes to the GitHub site.

##### Learning about Destructuring #####

    function randomInstrument() {
	const keys = Object.keys(instruments);
	const name = keys[Math.floor(Math.random() * keys.length)];
	const instrument = instruments[name];
	return { instrument, name };
	}

    function selectRandom() {
	const { instrument, name } = randomInstrument();

The line: return { instrument, name }; is the same as saying return {instrument: instrument, name: name} - it returns an object with those two values as set in the function, instrument and name. 

The line: const { instrument, name } = randomInstrument(); creates the variable "instrument" and sets it equal to the return value of  I could call: let result = randomInstrument() and then const name = result.name; const instrument = result.instrument; and it would do the same thing.

Remember: in calling const { instrument, name }, the property names MUST match.

##### Design Decisions #####

Removed "piano" option because it isn't a sustained instrument and it's not a band instrument. 

Also removed "piccolo" because of range and tone issues - may add back in later.

Maybe consider 500 or 600 pixel height instead of 400.

Removed "range" option - too complex for the scope of this project, AND if users want to practice a specific range, they could do so by selecting instruments in that range.

So how do I handle the "tuba, flute, unison" problem? I suppose, since it's the only combination that creates an issue, to run a rangeCompatible() check when the user selects "unison" that only checks for: if primary = tuba && if secondary = flute || if primary = flute && secondary && tuba {displayWarningText(); disableGameButton(); That would force the user to choose another option or choose other instruments.

##### Welcome Back! ##### 7/27/2025

TL;DR: gamemode.html is a prototype of game structure, website_ui2.html for user interface, each with a separate css file. script and data js files for instruments and functionality. 

It has been a month at least since I've looked at this project. Today, I remade all of the audio assets by using TonalEnergy sounds manually played through BlueTooth into Audacity on my computer to a metronome at 60bpm. This will have to work for now. It's the best audio I could find without vibrato. Maybe at some point in the future, I can slowly work toward creating audio assets using actual musicians playing in a studio setting, but not before I create a finished working product.

Let's take stock of where we're at and where we need to go. I have two main prototypes. WEBSITE_UI.HTML is what I used to create a navigable website with different UIs for a welcome screen, main game mode screen, an options screen, and another options screen for instrument selection. WEBSITE_UI2.HTML added checkbox functionality for the instrument selection screen. GAMEMODE.HTML is what I used to create a working prototype without any options, just the game cycle in easy mode. This allowed me to test the in/out stage and sharp/flat stage, with replay audio button and providing user feedback on correct and incorrect answers.

My AUDIOTEST.HTML file allows me to manually choose which instrument and note to play. I plan to continue using this file as I edit and export all of my note sound files, so that I can check for sound quality early rather than edit everything and then have to go back to fix problems. Question I have: does -6dB sound louder at higher frequencies? Like C2 at -6dB versus C5 or C7? Also, I decided to just stick with ONE VERSION of each audio file. I don't think, especially with the computer generated audio, that having Bb4-a and Bb4-b is really going to sound much different than just playing the same file twice, especially since I will be panning it from left and right speakers.

Now, one of the big issues I was wrestling with before I paused this project was how to deal with users selecting tuba and flute (no overlapping notes) and unison. Rather than trying to come up with some logical check and forcing users to figure it out, I think I've settled on the simple solution: users will be able to select ONE INSTRUMENT for both primary and secondary, rather than being able to select one for primary and a different for secondary. This still allows users to choose something like "Flute" so they can practice that instrument specifically. I still don't know if I'll let users choose multiple instruments, or maybe include buttons that select "upper brass" "upper woodwinds" "LB" "LWW" as a batch option. I don't know if I want to have a "high" "medium" "low" option that picks notes from specific octaves (1-3, 3-5, 5-7).

The GENERATE_BOTH.HTML file helped me figure out how to pick a random first tone, decide unison or octave, and then pick a second tone. INTONATION_TRAINER.HTML helped me figure out the gameplay structure. TESTTABLE.HTML helped me figure out how to populate a table, and BUILDTABLE.HTML helped me add functionality to the table. UI_TEST.HTML was an intermediary step towards the main prototype.

For my CSS files, I have gamemode.css that is used with gamemode.html and website_ui.css that is used with website_ui2.html. These are separate documents, and I made website_ui first. gamemode was an attempt of recreating a new but similar feel without copying anything directly, focused on the simplified format of gamemode.html.

Finally, I have some JavaScript (.js) files. DATA.JS includes information about instruments. Note that I changed the naming convention to include lower case and hyphens, like "alto-sax", to help with populating tables. I may still need to change my audio folder names to match (I am still only working with flute, trumpet, baritone, but that will soon change). SCRIPT.JS contains the main playback functions, parsing notes, selecting random instruments and notes. TIMERSCRIPT.JS was a result of adding a timer to my gamemode.html prototype, and simply starts a timer when called.

- - - - - - - - - - - - - - - - - 

To finish the project:
1) Export a small representative batch of audio assets (maybe "all Fs" for every instrument) and test for audio quality with AUDIOTEST.HTML. Are volumes equal between octaves? Does "in tune" sound in tune? How small of a difference for "hard" difficulty, 5 cents, 3 cents, 1 cent?
2) Continue to develop GAMEMODE.HTML to add options screen and functionality, finalize style decisions.

Decisions:
a) Is there a way to make it so that users can choose EITHER by instrument or by range? Maybe Instrument could be a drop-down menu, only able to select one at a time, but add "woodwinds" or "brass" or "all".
b) Do we make an ending? Like, play to 10 points? Play for timer? I had "free play" "countdown" and "challenge" earlier. 
